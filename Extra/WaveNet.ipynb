{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WaveNet\n",
    "\n",
    "In This lecture, we will be improving the performance of the model even further by implementing WaveNet architecture. While original purpose of this architecture is for Raw Audio, it can bring improvements to tasks where patterns over long sequences need to be learnt. \n",
    "\n",
    "In essence, WaveNet allows us to efficiently learn from longer sequences of input data due to its use of dilated causal convolutions, which expand the model's receptive field without a corresponding increase in computational complexity. This capability enables the model to capture and generate detailed and nuanced patterns that are essential for producing high-quality, realistic sequences, making it suitable for a variety of applications beyond audio, such as weather forecasting, financial time series prediction, and more.\n",
    "\n",
    "So the 3 Key features of the architecture are as follows: \n",
    "1) Dilated Convolution\n",
    "    * Dilated convolution is a technique where the convolutional kernel is applied over an area larger than its actual size by skipping input values at a regular interval. This is controlled by the dilation rate, which dictates the spacing between the points in the data that the filter covers.\n",
    "        * Consider a 1-dimensional sequence of audio samples. Using a dilated convolution with a dilation rate of 2 and a kernel size of 3, the convolutional filter would cover elements at positions [1, 3, 5] instead of [1, 2, 3]. This effectively allows the filter to 'see' more data without increasing the kernel size.\n",
    "    * This approach enables the model to have a wider receptive field, allowing it to capture long-range dependencies in the data without significantly increasing computational complexity or the number of parameters. This is particularly useful in processing audio, where understanding context from a larger sequence is crucial for generating coherent sounds.\n",
    "2) Causal Convolutions\n",
    "    * Causal convolutions ensure that the output at any point is only dependent on past and present inputs, not future inputs. This is achieved by padding the input sequence on the left (for time series data) and not on the right, aligning the output with the input in such a way that it only depends on what has come before it.\n",
    "        * In a speech generation model, when predicting the next audio sample at time t, a causal convolution would use only the samples from time t−1, t−2, etc., ensuring that the generation process is temporally coherent and realistic.\n",
    "    * Causal convolutions are useful for any generative model where the sequence must be generated in a forward direction, as in speech or music. This ensures that the model does not cheat by using future information, thereby making the model suitable for real-time applications.\n",
    "3) Autoregressive Models\n",
    "    * In autoregressive models, each output is predicted based on previous outputs. The model regresses on its own outputs, using past values to predict future values in a sequence.\n",
    "        * In WaveNet, each new audio sample is generated based on all previously generated samples. For example, to generate the next sound in a speech sequence, the model looks at the previously generated sounds and computes the most likely next sound based on that history.\n",
    "    * Autoregressive modeling allows for detailed and nuanced control over the generation process, as each step in the sequence can refine the prediction based on the accumulated context. This is crucial for producing high-quality, realistic audio sequences where each sound is a continuation of what was previously heard.\n",
    "\n",
    "The Flattening Scheme that we are going to use is shown in the Figure below: \n",
    "<center><img src=\"./images_WaveNet/WaveNet.png\" width=\"600\" alt=\"Example\" /></center>\n",
    "\n",
    "Additionally the original paper can be found here: https://arxiv.org/pdf/1609.03499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan for the lecture\n",
    "\n",
    "##### Part 0 - Review\n",
    "\n",
    "0) importing the code from previous lectures\n",
    "\n",
    "##### Part 1 - Fixing up the code, to make it more respectable and PyTorch compliant\n",
    "\n",
    "0) Forward Pass \n",
    "1) Lack of structure when defining a neural network, a very \"Naked\" List\n",
    "\n",
    "##### Part 2 - Incorporating The WaveNet Architecture\n",
    "\n",
    "0) Reworking the flattening layer\n",
    "1) Reworking the BatchNorm as a bug will appear due to change in structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 0 - Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "words = open(\"./names.txt\", \"r\").read().splitlines()\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# Creating the Dataset\n",
    "\n",
    "import random\n",
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "\n",
    "            ix = stoi[ch]\n",
    "\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ----> y\n",
      "..y ----> u\n",
      ".yu ----> h\n",
      "yuh ----> e\n",
      "uhe ----> n\n",
      "hen ----> g\n",
      "eng ----> .\n",
      "... ----> d\n",
      "..d ----> i\n",
      ".di ----> o\n",
      "dio ----> n\n",
      "ion ----> d\n",
      "ond ----> r\n",
      "ndr ----> e\n",
      "dre ----> .\n"
     ]
    }
   ],
   "source": [
    "# Showcasing Input/Output relationships created in datasets\n",
    "\n",
    "for x, y in zip(Xtr[:14], Ytr[:14]):\n",
    "    print(\"\".join(itos[ix.item()] for ix in x), \"---->\", itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers made in part 3\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out))\n",
    "        self.weight /= fan_in ** 0.5\n",
    "        self.bias = torch.zeros((fan_out)) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "        # buffers (trained while running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            # batch mean\n",
    "            xmean = x.mean(0, keepdim=True)\n",
    "            # batch variance\n",
    "            xvar = x.var(0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        # update the buffers in training\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * \\\n",
    "                    self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * \\\n",
    "                    self.running_var + self.momentum * xvar\n",
    "\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17790cd9170>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters: 12097\n"
     ]
    }
   ],
   "source": [
    "# Constructing the Neural Network with our Layers as building blocks \n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd))\n",
    "layers = [\n",
    "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = [C] + [p for l in layers for p in l.parameters()]\n",
    "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 3.313666343688965\n"
     ]
    }
   ],
   "source": [
    "# Training part\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb]  # embed characters into vector space\n",
    "    x = emb.view((emb.shape[0], -1))  # flatten\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    # compute loss\n",
    "    loss = F.cross_entropy(x, Yb)\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad()\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 10000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"step {i} loss {loss.item()}\")\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1 - Fixing up the code, to make it more respectable and PyTorch compliant\n",
    "\n",
    "1) implementing classes \"Embedding\" and \"Flatten\" we make the code less gnarly to look at and understand.\n",
    "2) implementing class \"Sequential\" we give the naked list some needed structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers made in part 3\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out))\n",
    "        self.weight /= fan_in ** 0.5\n",
    "        self.bias = torch.zeros((fan_out)) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "        # buffers (trained while running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            # batch mean\n",
    "            xmean = x.mean(0, keepdim=True)\n",
    "            # batch variance\n",
    "            xvar = x.var(0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        # update the buffers in training\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * \\\n",
    "                    self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * \\\n",
    "                    self.running_var + self.momentum * xvar\n",
    "\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# ---------------- new ----------------\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view((x.shape[0], -1))\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can observe how much cleaner this allows our code to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters: 12097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    Flatten(),\n",
    "\n",
    "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "update_to_data_ratio = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "    # forward pass is now simpler\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 10000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"step {i} loss {loss.item()}\")\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 3.5926153659820557\n",
      "valid 3.591214656829834\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model \n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.training = False\n",
    "    \n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        \"train\": (Xtr, Ytr),\n",
    "        \"valid\": (Xdev, Ydev),\n",
    "        \"test\": (Xte, Yte)\n",
    "    }[split]\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "print(\"train\", split_loss(\"train\"))\n",
    "print(\"valid\", split_loss(\"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oznwarqscznyamf\n",
      "gvacyovflqeqrhtnnufiprammkjaxvizntzvzhp\n",
      "ousrxxlpplrrqvhzixwpyzryhtmpuifgnspy\n",
      "u\n",
      "boomkjnrkmxprzpcwbzfqrmvnkkhixyyd\n",
      "qeukluadtnzd\n",
      "gajwpyme\n",
      "e\n",
      "i\n",
      "s\n",
      "negyyncwawjyizzajwsmqdnvixqraqpqkuihopyfxhsxvynevvxxozvhqincyyow\n",
      "ujabmpzrbdfvvxzivxscjcrnxutpy\n",
      "snatmedhfvhczfxycpvgocnehgulwfyasgakbbfsuitajcyrokfdpeymlniqkfmhrukhkrkfpplakeikriipcighaskfqitszavhwaozdmaywhe\n",
      "uutkqursuznrunqjpyzvdqjzedeyeocjwjktjnhxxuzmt\n",
      "vp\n",
      "l\n",
      "\n",
      "vnkwmeidvrnwbibmookbedxnrkhdgzmkwzhugas\n",
      "smayqcjwgmkzfnwwmkfwdfebmljxqeptfffnmfpdhetdwdajfftdhstkjpz\n",
      "nj\n"
     ]
    }
   ],
   "source": [
    "# sampling from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        # Forward pass\n",
    "        logits = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        # Shift the Context Window\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "        out.append(ix)\n",
    "\n",
    "    print(\"\".join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2 - Incorporating WaveNet Architecture\n",
    "\n",
    "<center><img src=\"./images_WaveNet/WaveNet.png\" width=\"600\" alt=\"Example\" /></center>\n",
    "\n",
    "We will be changing the 'block_size' to 8 from 3, in order to better understand the benefits of wavenet on longer sequences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 8]) torch.Size([182580])\n",
      "torch.Size([22767, 8]) torch.Size([22767])\n",
      "torch.Size([22799, 8]) torch.Size([22799])\n",
      "........ ----> e\n",
      ".......e ----> b\n",
      "......eb ----> r\n",
      ".....ebr ----> i\n",
      "....ebri ----> m\n",
      "...ebrim ----> a\n",
      "..ebrima ----> .\n",
      "........ ----> h\n",
      ".......h ----> i\n",
      "......hi ----> l\n",
      ".....hil ----> t\n",
      "....hilt ----> o\n",
      "...hilto ----> n\n",
      "..hilton ----> .\n",
      "........ ----> j\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "\n",
    "            ix = stoi[ch]\n",
    "\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n",
    "\n",
    "for x, y in zip(Xtr[:15], Ytr[:15]):\n",
    "    print(\"\".join(itos[ix.item()] for ix in x), \"---->\", itos[y.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the network, without architectural changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters: 22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    Flatten(),\n",
    "\n",
    "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  6,  6,  1, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0, 25,  9,  1, 14]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of 4 examples, each containing 8 numbers that denote the characters, Those 8 characters are part of the Input in the I/O pairs of the training dataset. \n",
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding has output size of: torch.Size([4, 8, 10])\n",
      "Flatten has output size of: torch.Size([4, 80])\n",
      "Linear has output size of: torch.Size([4, 200])\n",
      "BatchNorm1d has output size of: torch.Size([4, 200])\n",
      "Tanh has output size of: torch.Size([4, 200])\n",
      "Linear has output size of: torch.Size([4, 27])\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"{layer.__class__.__name__} has output size of: {layer.out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Layer has the output in the shape of [4, 8, 10], because every one of the 8 characters passed in is transformed into a 10 dimensional vector. After this the flattening layer flattens all 8 characters into 1 long vector, causing the final shape to be [4, 80]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current set up with the flattening layer means that we process 8 characters at the same time, which is not our goal according to the figure. Rather, our goal is to process them in X groups of 2 characters, until we converge to 1 group of 2 characters for our final output. \n",
    "\n",
    "so in the first layer instead of processing \n",
    "\n",
    "1 2 3 4 5 6 7 8\n",
    "\n",
    "we will process \n",
    "\n",
    "(1 2) (3 4) (5 6) (7 8)\n",
    "\n",
    "in essence this means that instead of multiplying (4, 80) @ (80, 200) = (4, 200), we multiply (4, 4, 20) @ (80, 200) = (4, 4, 200). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are several ways we can achieve the shape of input that we seek, both explicit and implicit.\n",
    "\n",
    "# output of layer 0\n",
    "e = torch.randn(4, 8, 10)\n",
    "# contacenate even and odd (on character dimension) elements of the last dimension\n",
    "explicit = torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2)\n",
    "# you can do the same using view\n",
    "implicit = e.view(4, 4, 20)\n",
    "\n",
    "(implicit == explicit).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we reimplement the flattening layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplement Flatten\n",
    "class FlattenConsecutive:\n",
    "    def __init__(self, n):\n",
    "        # n is the number of consecutive elements we want (2 in our example)\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # in our example: B = 4, T = 8, C = 10\n",
    "        B, T, C = x.shape\n",
    "        # we want to convert X to (4, 4, 20)\n",
    "        x = x.view(B, T // self.n, C * self.n)\n",
    "\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters: 22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "# changing the number of hidden units to 68 keeps the same number of parameters as the previous model (22k)\n",
    "n_hidden = 68\n",
    "\n",
    "# if we were to initialize FlattenConsecutive(block_size), it will still go ahead and flatten the entire input into one long vector\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0, 10,  1],\n",
       "        [ 0,  0,  0, 18,  1, 25, 12, 25],\n",
       "        [ 0,  0,  5, 12, 14, 15, 18,  1],\n",
       "        [ 0,  0,  0,  0,  0, 26,  1,  5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding has output size of: torch.Size([4, 8, 10])\n",
      "FlattenConsecutive has output size of: torch.Size([4, 80])\n",
      "Linear has output size of: torch.Size([4, 200])\n",
      "BatchNorm1d has output size of: torch.Size([4, 200])\n",
      "Tanh has output size of: torch.Size([4, 200])\n",
      "Linear has output size of: torch.Size([4, 27])\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"{layer.__class__.__name__} has output size of: {layer.out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a bug that needs to be addressed with BatchNormalization\n",
    "\n",
    "The bug is due to the fact that our batchnormalization was written for 2 dimensional input only, as soon as 3 dimensional input enters, you may expect suboptimal performance. The Mean and Variance in previous implemention is calculated for first dimension only, we want to calculate it over the 2nd dimension as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 68])\n",
      "shape of running mean is torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "e = torch.rand(32, 4, 68)\n",
    "emean = e.mean(dim=(0, 1), keepdim=True)  # (1, 1, 68)\n",
    "evar = e.var((0, 1), keepdim=True)  # (1, 1, 68)\n",
    "ehat = (e - emean) / torch.sqrt(evar + 1e-5)\n",
    "\n",
    "print(ehat.shape)\n",
    "print(f\"shape of running mean is {model.layers[3].running_mean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "        # buffers (trained while running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            # determine the dimension to reduce over\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "\n",
    "            xmean = x.mean(dim, keepdim=True)\n",
    "            # batch variance\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        # update the buffers in training\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * \\\n",
    "                    self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * \\\n",
    "                    self.running_var + self.momentum * xvar\n",
    "\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters: 22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "# changing the number of hidden units to 68 keeps the same number of parameters as the previous model (22k)\n",
    "n_hidden = 68\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(f\"num parameters: {sum(p.numel() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's Summarize our progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers made in part 3\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out))\n",
    "        self.weight /= fan_in ** 0.5\n",
    "        self.bias = torch.zeros((fan_out)) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "        # buffers (trained while running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            # determine the dimension to reduce over\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "\n",
    "            xmean = x.mean(dim, keepdim=True)\n",
    "            # batch variance\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        # update the buffers in training\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * \\\n",
    "                    self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * \\\n",
    "                    self.running_var + self.momentum * xvar\n",
    "\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view((x.shape[0], -1))\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "\n",
    "class FlattenConsecutive:\n",
    "    def __init__(self, n):\n",
    "        # n is the number of consecutive elements we want (2 in our example)\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # in our example: B = 4, T = 8, C = 10\n",
    "        B, T, C = x.shape\n",
    "        # we want to convert X to (4, 4, 20)\n",
    "        x = x.view(B, T // self.n, C * self.n)\n",
    "\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24\n",
    "n_hidden = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden,\n",
    "                                  bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1  # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3122\n",
      "  10000/ 200000: 1.8999\n",
      "  20000/ 200000: 2.1902\n",
      "  30000/ 200000: 1.8471\n",
      "  40000/ 200000: 2.3311\n",
      "  50000/ 200000: 2.2637\n",
      "  60000/ 200000: 2.1406\n",
      "  70000/ 200000: 2.0446\n",
      "  80000/ 200000: 2.0532\n",
      "  90000/ 200000: 2.0178\n",
      " 100000/ 200000: 1.6284\n",
      " 110000/ 200000: 1.8973\n",
      " 120000/ 200000: 1.8976\n",
      " 130000/ 200000: 2.0712\n",
      " 140000/ 200000: 1.9213\n",
      " 150000/ 200000: 1.7763\n",
      " 160000/ 200000: 1.9869\n",
      " 170000/ 200000: 1.8898\n",
      " 180000/ 200000: 1.5488\n",
      " 190000/ 200000: 1.4480\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb)  # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update: simple SGD\n",
    "    lr = 0.1 if i < 150000 else 0.01  # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0:  # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1778fbbce50>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1, keepdim=True).data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.7672295570373535\n",
      "valid 1.9881629943847656\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False\n",
    "    \n",
    "print(\"train\", split_loss(\"train\"))\n",
    "print(\"valid\", split_loss(\"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nogha\n",
      "lowing\n",
      "arcansour\n",
      "noaly\n",
      "milena\n",
      "deleann\n",
      "lindsha\n",
      "spenan\n",
      "elyash\n",
      "autumn\n",
      "roccael\n",
      "brexel\n",
      "manuello\n",
      "horatin\n",
      "miazi\n",
      "alanova\n",
      "mel\n",
      "johnce\n",
      "mikjoh\n",
      "ryon\n"
     ]
    }
   ],
   "source": [
    "# sampling from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        # Forward pass\n",
    "        logits = model(torch.tensor([context]).reshape(1, -1))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        # Shift the Context Window\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "        out.append(ix)\n",
    "\n",
    "    print(\"\".join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
